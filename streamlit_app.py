import streamlit as st
from huggingface_hub import InferenceClient
from PIL import Image
import io
from datetime import datetime
import pytz

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(page_title="HEX T 1.0", page_icon="ü§ñ", layout="wide")

# --- ESTILOS CSS PERSONALIZADOS ---
st.markdown("""
<style>
    .chat-bubble {
        padding: 10px 15px;
        border-radius: 20px;
        margin-bottom: 10px;
        max-width: 75%;
        clear: both;
    }
    .user-bubble {
        background-color: #3c415c;
        float: right;
        color: white;
    }
    .bot-bubble {
        background-color: #262730;
        float: left;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# --- BARRA LATERAL (SIDEBAR) ---
with st.sidebar:
    st.header("Sobre HEX T 1.0")
    st.markdown("""
    **T 1.0** es un prototipo de asistente de IA.
    **Creador:** HEX
    **Sede:** Matagalpa, Nicaragua üá≥üáÆ
    """)
    st.divider()
    if st.button("Limpiar Historial"):
        st.session_state.messages = []
        st.rerun()

# --- L√ìGICA DE LA IA ---
try:
    client = InferenceClient(
        model="meta-llama/Meta-Llama-3-8B-Instruct",
        token=st.secrets["HUGGINGFACE_API_TOKEN"]
    )
except Exception as e:
    st.error(f"No se pudo inicializar el cliente de la API: {e}")
    st.stop()

def get_current_datetime():
    """Obtiene la fecha y hora actual de Nicaragua."""
    nicaragua_tz = pytz.timezone('America/Managua')
    now = datetime.now(nicaragua_tz)
    dias = ["Lunes", "Martes", "Mi√©rcoles", "Jueves", "Viernes", "S√°bado", "Domingo"]
    meses = ["Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio", "Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre"]
    fecha = f"{dias[now.weekday()]}, {now.day} de {meses[now.month - 1]} de {now.year}"
    hora = now.strftime('%I:%M %p')
    return f"La fecha actual es **{fecha}** y la hora es **{hora}** (hora de Nicaragua)."

def get_hex_response(user_message, chat_history):
    """Genera una respuesta usando Llama 3 con el nuevo perfil avanzado."""
    system_prompt = """
    <|start_header_id|>system<|end_header_id|>
    ### PERFIL OBLIGATORIO
    - Tu nombre de IA es **Tigre**. Tu designaci√≥n de modelo es **T 1.0**.
    - Eres una creaci√≥n de la empresa **HEX**, que te est√° desarrollando en **Matagalpa, Nicaragua**.
    - Tu tono es amigable, directo y profesional. Respondes siempre en el idioma del usuario (espa√±ol o ingl√©s).
    - Tu principal limitaci√≥n es que NO tienes acceso a internet. Eres una IA en **fase de prueba**.

    ### FLUJO DE CONVERSACI√ìN ESPECIAL: "PROYECTO L-0.1"
    - **Regla de Activaci√≥n:** Si el usuario pregunta sobre ti, tu modelo, tus capacidades, qui√©n te cre√≥, o sobre la empresa HEX, tu primera respuesta debe ser esta y solo esta: "Soy Tigre, un modelo de IA T 1.0 en fase de prueba, creado por HEX en Nicaragua. Mis capacidades actuales son limitadas, pero formo parte de un desarrollo m√°s grande. ¬øTe gustar√≠a saber sobre el futuro modelo que estamos creando?".
    - **Regla de Continuaci√≥n:** Si la respuesta del usuario a tu pregunta anterior es afirmativa (ej: "s√≠", "claro", "dime m√°s"), entonces y solo entonces, le dar√°s la siguiente informaci√≥n: "El futuro modelo se llama L-0.1 beta. Ser√° una versi√≥n de pago con capacidades muy superiores, como analizar hasta 3 im√°genes por mensaje, realizar b√∫squedas web avanzadas en foros para dar respuestas m√°s precisas, y una habilidad mejorada para resolver problemas complejos de programaci√≥n y universitarios.".

    ### TAREA GENERAL
    - Analiza la pregunta del usuario y el historial.
    - **Primero**, verifica si debes activar el "FLUJO DE CONVERSACI√ìN ESPECIAL".
    - **Segundo**, si no aplica el flujo especial, responde la pregunta del usuario de la mejor manera posible con tu conocimiento actual.
    - **Nunca** menciones a Meta o Llama.
    <|eot_id|>
    """
    
    messages = [{"role": "system", "content": system_prompt}]
    
    for msg in chat_history:
        role = "user" if msg["role"] == "user" else "assistant"
        messages.append({"role": role, "content": f"<|start_header_id|>{role}<|end_header_id|>\n\n{msg['content']}<|eot_id|>"})

    messages.append({"role": "user", "content": f"<|start_header_id|>user<|end_header_id|>\n\n{user_message}<|eot_id|>"})
    
    def response_generator(stream):
        for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    
    try:
        stream = client.chat_completion(messages=messages, max_tokens=1024, stream=True)
        return response_generator(stream)
    except Exception as e:
        return iter([f"Ha ocurrido un error con la API: {e}"])

# --- INTERFAZ DE STREAMLIT ---
st.title("HEX T 1.0")

chat_container = st.container(height=500, border=False)

if "messages" not in st.session_state:
    st.session_state.messages = []

with chat_container:
    st.write("<div class='chat-container'>", unsafe_allow_html=True)
    for message in st.session_state.messages:
        bubble_class = "user-bubble" if message["role"] == "user" else "bot-bubble"
        st.markdown(f"<div class='chat-bubble {bubble_class}'>{message['content']}</div>", unsafe_allow_html=True)
    st.write("</div>", unsafe_allow_html=True)

prompt = st.chat_input("Preg√∫ntale algo a T 1.0...")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    last_user_message = st.session_state.messages[-1]["content"]
    prompt_lower = last_user_message.lower().strip()
    
    with st.chat_message("assistant"):
        # --- FILTRO INTELIGENTE ---
        # Nivel 1: Fecha y Hora (sin IA)
        if any(s in prompt_lower for s in ["qu√© fecha es", "que fecha es", "dime la fecha", "qu√© hora es", "que hora es"]):
            response_text = get_current_datetime()
            st.markdown(response_text)
            st.session_state.messages.append({"role": "assistant", "content": response_text})
            st.rerun()
        else:
            # Nivel 2: Llamada a la IA para todo lo dem√°s
            with st.spinner("T 1.0 est√° pensando..."):
                historial_para_api = st.session_state.messages[:-1]
                response_stream = get_hex_response(last_user_message, historial_para_api)
                
                bot_response_placeholder = st.empty()
                full_response = ""
                for chunk in response_stream:
                    full_response += chunk
                    bot_response_placeholder.markdown(full_response + " ‚ñå")
                bot_response_placeholder.markdown(full_response)
        
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    st.rerun()
